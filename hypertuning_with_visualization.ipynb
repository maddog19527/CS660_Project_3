{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Install Packages'''\n",
    "!pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Imports'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from prettytable import PrettyTable\n",
    "import graphviz\n",
    "\n",
    "'''Import Utils'''\n",
    "\n",
    "\n",
    "'''Import Data'''\n",
    "from sklearn.datasets import load_digits, fetch_california_housing\n",
    "\n",
    "'''Import Data Processing Utilities'''\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''Import Predictors'''\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "'''Import Tuning Utilities'''\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "from skopt.space import Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence, plot_gaussian_process\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Scoring Criteria Space'''\n",
    "scoringCriteria = [\n",
    "    'positive_likelihood_ratio', 'f1_micro', 'v_measure_score', 'roc_auc_ovr_weighted',\n",
    "    'adjusted_rand_score', 'neg_mean_squared_log_error', 'r2', 'precision_macro',\n",
    "    'roc_auc_ovo_weighted', 'neg_median_absolute_error', 'matthews_corrcoef', 'precision_samples',\n",
    "    'jaccard_micro', 'balanced_accuracy', 'precision_micro', 'recall_micro', 'f1_samples',\n",
    "    'recall', 'jaccard', 'neg_mean_poisson_deviance', 'rand_score', 'jaccard_weighted',\n",
    "    'neg_mean_absolute_percentage_error', 'precision_weighted', 'average_precision',\n",
    "    'neg_log_loss', 'recall_samples', 'recall_weighted', 'accuracy', 'homogeneity_score',\n",
    "    'neg_mean_absolute_error', 'adjusted_mutual_info_score', 'roc_auc', 'completeness_score',\n",
    "    'f1_macro', 'roc_auc_ovo', 'recall_macro', 'top_k_accuracy', 'f1', 'roc_auc_ovr',\n",
    "    'normalized_mutual_info_score', 'fowlkes_mallows_score', 'mutual_info_score', 'explained_variance',\n",
    "    'max_error', 'neg_negative_likelihood_ratio', 'neg_brier_score', 'neg_mean_squared_error',\n",
    "    'f1_weighted', 'neg_root_mean_squared_error', 'jaccard_samples', 'neg_mean_gamma_deviance',\n",
    "    'jaccard_macro', 'precision'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fetch Regressor Data'''\n",
    "cal_housing = fetch_california_housing(as_frame=True)\n",
    "# print(cal_housing.data)\n",
    "# print(cal_housing.target)\n",
    "print(cal_housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Regressor data EDA: Outliers'''\n",
    "\n",
    "outlierTable = PrettyTable(['Feature', 'Outlier Count'])\n",
    "\n",
    "for column in cal_housing.data.columns:\n",
    "    Q1 = cal_housing.data[column].quantile(0.25)\n",
    "    Q3 = cal_housing.data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5*IQR\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    outlierCount = np.array(cal_housing.data[column] >= upper).sum() + np.array(cal_housing.data[column] <= lower).sum()\n",
    "    outlierTable.add_row([column, outlierCount])\n",
    "    # print(f\"{column}: {outlierCount}\")\n",
    "\n",
    "print(outlierTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Cleaning and Pre-Processing: Outlier Removal'''\n",
    "cleanData = cal_housing.data\n",
    "cleanData['y'] = cal_housing.target\n",
    "\n",
    "# cleanData = cleanData.drop(columns=['Longitude', 'Latitude'])\n",
    "for feature in ['AveBedrms', 'AveRooms', 'AveOccup', 'Population']:\n",
    "    cleanData = cleanData[(np.abs(stats.zscore(cleanData[feature])) < 2.5)]\n",
    "\n",
    "# DATA CLEANING TODOs\n",
    "# TODO: Bin Lat/Long groupings into city/town clusters. look for available geo-fencing data for cluster labeling - can we do a graph of centroids on top of map?\n",
    "# TODO: Fix Skew for Population, MedIncome, AvgOccup, AvgBedroom, Target\n",
    "# TODO: Feature Engineering / Reduction\n",
    "\n",
    "cleanTarget = cleanData['y'].to_list()\n",
    "cleanData.drop(columns=['y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData = cleanData.copy()\n",
    "\n",
    "# paramSpace = {\n",
    "#             'regress__criterion': ['squared_error','poisson'],\n",
    "#             'regress__max_depth': Integer(500,1000),\n",
    "#             'regress__min_samples_split': Real(0.1, 0.3),\n",
    "#             'regress__min_samples_leaf': Real(0.1, 0.4),\n",
    "#             'regress__max_features': Real(0.4, 0.9),\n",
    "#             'pca__n_components': Integer(1,len(cleanData.columns)),\n",
    "#             'scaler__with_mean': [True, False],\n",
    "#             'scaler__with_std': [True, False],\n",
    "#         }\n",
    "paramSpace = {\n",
    "            'criterion': ['squared_error','poisson'],\n",
    "            'max_depth': Integer(500,1000),\n",
    "            'min_samples_split': Real(0.1, 0.3),\n",
    "            'min_samples_leaf': Real(0.1, 0.4),\n",
    "            'max_features': Real(0.4, 0.9),\n",
    "        }\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(modelData, cleanTarget, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    # pipe,\n",
    "    DecisionTreeRegressor(),\n",
    "    paramSpace,\n",
    "    n_iter=30,\n",
    "    cv=10,\n",
    "    )\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True)),\n",
    "    ('regress',opt)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# predicted = opt.best_estimator_.predict(X_test)\n",
    "# opt = pipe.steps[-1][-1]\n",
    "print('Evaluation Metric:', opt.get_params()['scoring'])\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))\n",
    "\n",
    "# .setps only applies when a sklearn pipe is uesed.\n",
    "# bestEstimator = opt.best_estimator_.steps[-1][1]\n",
    "bestEstimator = opt.best_estimator_\n",
    "features = modelData.columns\n",
    "importance = bestEstimator.feature_importances_\n",
    "\n",
    "if(len(features) == len(importance)):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(list(modelData.columns), importance)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "\n",
    "ax = plot_convergence(\n",
    "                opt.optimizer_results_[0],\n",
    "                # n_minimum_search=int(1e8)\n",
    "                )\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()\n",
    "\n",
    "# if(len(features) == len(importance)):\n",
    "# opt.best_estimator_.steps[-1][-1],filled=True,rounded=True,special_characters=True,\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    opt.best_estimator_,filled=True,rounded=True,special_characters=True,\n",
    "    feature_names=modelData.columns)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "plt.show()\n",
    "\n",
    "ax = plot_objective(\n",
    "                opt.optimizer_results_[0],\n",
    "                n_minimum_search=int(1e8)\n",
    "                )\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "from sklearn.tree import export_text, plot_tree, export_graphviz, decision_path\n",
    "import graphviz\n",
    "\n",
    "\n",
    "# export_text(opt.best_estimator_,\n",
    "#             feature_names=['MedInc','HouseAge','AveRooms','AveBedrms',\n",
    "#                            'Population','AveOccup','Latitude','Longitude'])\n",
    "\n",
    "# plot_tree(opt.best_estimator_,\n",
    "#             feature_names=['MedInc','HouseAge','AveRooms','AveBedrms',\n",
    "#                            'Population','AveOccup','Latitude','Longitude'])\n",
    "\n",
    "# opt.best_estimator_.steps[-1][-1],filled=True,rounded=True,special_characters=True,\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    opt.best_estimator_,filled=True,rounded=True,special_characters=True,\n",
    "    feature_names=modelData.columns)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test[1:4])\n",
    "# for test in X_test[1:2]:\n",
    "#     print(test)\n",
    "# for test in X_test[0:-1]:\n",
    "#     node_indicator = opt.best_estimator_.decision_path(test)\n",
    "#     print(node_indicator)\n",
    "\n",
    "node_indicator = opt.best_estimator_.decision_path(X_test[1:10])\n",
    "print(node_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt.plots import plot_objective, plot_histogram, plot_convergence, plot_gaussian_process\n",
    "\n",
    "ax = plot_convergence(\n",
    "                opt.optimizer_results_[0],\n",
    "                # n_minimum_search=int(1e8)\n",
    "                )\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt.plots import plot_objective, plot_histogram, plot_convergence, plot_gaussian_process\n",
    "\n",
    "ax = plot_objective(\n",
    "                opt.optimizer_results_[0],\n",
    "                n_minimum_search=int(1e8)\n",
    "                )\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = opt.best_estimator_.steps[-1][1]\n",
    "features = modelData.columns\n",
    "importance = regressor.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(list(modelData.columns), importance)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = opt.best_estimator_.steps[-1][-1]\n",
    "\n",
    "importance = regressor.feature_importances_\n",
    "\n",
    "# print(regressor.cost_complexity_pruning_path(X_test, y_test))\n",
    "\n",
    "# print(regressor.features)\n",
    "print(len(importance))\n",
    "\n",
    "opt.feature_names_in_\n",
    "\n",
    "plot_tree(regressor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
