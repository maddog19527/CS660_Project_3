{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from utils.utils import encode\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "df_digits = pd.DataFrame(digits.data, columns=[f'Pixel_{i}' for i in range(digits.data.shape[1])])\n",
    "df_digits['Target'] = digits.target\n",
    "\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "X_housing = housing.data  \n",
    "y_housing = housing.target  \n",
    "df_housing = pd.concat([X_housing, y_housing.rename('MedHouseVal')], axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Information Pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digits.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df_digits.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "print(f'\\nDuplicates: {df_digits.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df_housing.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Classification EDA Work--\n",
    "-Plotting value counts and distribution of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df_digits['Target'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values, palette='viridis')\n",
    "plt.title(\"Distribution of Target Digits\")\n",
    "plt.xlabel(\"Digits\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create correlation matrix and heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = df_digits.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix.iloc[:20, :20], annot=False, cmap='coolwarm', cbar=True, vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Heatmap (First 20 Pixels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Feature Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_variances = df_digits.var().drop('Target')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=range(len(feature_variances)), y=feature_variances, color='blue')\n",
    "plt.title(\"Feature Variances\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "low_variance_features = feature_variances[feature_variances < 0.1]\n",
    "print(\"\\nLow-variance features:\\n\", low_variance_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "digits_pca = pca.fit_transform(digits.data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=digits_pca[:, 0], y=digits_pca[:, 1], hue=digits.target, palette='tab10', s=60)\n",
    "plt.title(\"2D PCA Projection of Digits Dataset\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(title=\"Digits\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Filtering to Isolate '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "digit_zero = df_digits[df_digits['Target'] == 0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    sns.kdeplot(digit_zero[f'Pixel_{i}'], label=f'Pixel_{i}', fill=True)\n",
    "plt.title(\"Distribution of Pixel Values for Digit '0'\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel Pairplotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_pixels = ['Pixel_0', 'Pixel_10', 'Pixel_20', 'Pixel_30', 'Target']\n",
    "sns.pairplot(df_digits[selected_pixels], hue='Target', palette='tab10')\n",
    "plt.suptitle(\"Pairplot of Selected Pixels\", y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel Intensity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_pixel_intensity = df_digits.groupby('Target').mean().iloc[:, :64]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    digit_heatmap = mean_pixel_intensity.iloc[i].values.reshape(8, 8)\n",
    "    sns.heatmap(digit_heatmap, ax=ax, cmap='viridis', cbar=False, annot=False)\n",
    "    ax.set_title(f\"Digit: {i}\")\n",
    "    ax.axis('off')\n",
    "plt.title(\"Average Pixel Intensity for Each Digit\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Regression EDA Work--\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate and Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnivariateAnalysis(df):\n",
    "    columns = df.columns\n",
    "    n = len(columns)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(8, 6 * n))\n",
    "    for i, col in enumerate(columns):\n",
    "        sns.histplot(df[col], kde=True, bins=10, ax=axes[i])\n",
    "        axes[i].set_title(f'Histogram for {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(8, 6 * n))\n",
    "    for i, col in enumerate(columns):\n",
    "        sns.boxplot(x=df[col], ax=axes[i])\n",
    "        axes[i].set_title(f'Boxplot for {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "print(cal_df.shape)\n",
    "print(cal_df['Latitude'].nunique())\n",
    "print(cal_df['Longitude'].nunique())\n",
    "print(cal_df.head())\n",
    "print(cal_df.isnull().sum())\n",
    "\n",
    "UnivariateAnalysis(df_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BivariateAnalysis(df):\n",
    "    Pearson=df.corr(method='pearson')\n",
    "    Spearman=df.corr(method='spearman')\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(Pearson, annot=True)\n",
    "    plt.title(\"Pearson Correlation Index\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(Spearman, annot=True, cmap='coolwarm')\n",
    "    plt.title('Spearman Correlation Index')\n",
    "    plt.show()\n",
    "BivariateAnalysis(df_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplots demonstrating positive and negative correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PairPlots(df):\n",
    "  sns.pairplot(df, kind='reg', plot_kws={'line_kws':{'color': 'red'}})\n",
    "  plt.show()\n",
    "  \n",
    "selected=df_housing.drop(columns=['Latitude','Longitude','Population','Medvalue'])\n",
    "PairPlots(selected)\n",
    "\n",
    "Population=df_housing[['Population','Medvalue','MedInc','AveRooms','AveOccup']]\n",
    "sns.pairplot(Population,kind='reg', plot_kws={'line_kws':{'color': 'red'}})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier Detection Methods and Function comparing each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZOutliers(df):\n",
    "  zdf=df.copy()\n",
    "  outliers=pd.DataFrame()\n",
    "  for col in zdf.columns:\n",
    "    zscore=stats.zscore(zdf[col])\n",
    "    zdf[f'{col}_zscore']=zscore\n",
    "    mask=zdf[f'{col}_zscore'].abs()<2.5\n",
    "    zdf=zdf[mask]\n",
    "    # outliers.drop_duplicates(inplace=True)\n",
    "    # z_score_columns=[col for col in outliers.columns if col.endswith('_zscore')]\n",
    "    # outliers=outliers.drop(columns=z_score_columns)\n",
    "    # outliers.to_csv('outliers.csv', index=False)\n",
    "    zdf.drop(columns=[f'{col}_zscore'], inplace=True)\n",
    "\n",
    "  return zdf\n",
    "def OutlierDetection(df):\n",
    "  clean_df=df.copy()\n",
    "  outliers=pd.DataFrame()\n",
    "  for col in clean_df.columns:\n",
    "    Q1=df[col].quantile(0.25)\n",
    "    Q3=df[col].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    lower=Q1-1.5*IQR\n",
    "    upper=Q3+1.5*IQR\n",
    "    mask=(df[col] >= lower) & (df[col]<=upper)\n",
    "    clean_df=clean_df[mask]\n",
    "  return clean_df\n",
    "def KNNOutliers(df):\n",
    "  df1=df.copy()\n",
    "  combinedoutliers=pd.DataFrame()\n",
    "  for col in df.columns:\n",
    "    k=20\n",
    "    knn=KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(df1.iloc[:,1:9], df1[col])\n",
    "    distances,indeces=knn.kneighbors(df1.iloc[:,1:9])\n",
    "    df1[f'outlierscore for {col}']=np.mean(distances, axis=1)\n",
    "    threshold=np.percentile(np.mean(distances, axis=1), 95)\n",
    "    mask=df1[f'outlierscore for {col}']<threshold\n",
    "    df1=df1[mask]\n",
    "    df1.drop(columns=f'outlierscore for {col}', inplace=True)\n",
    "  return df1\n",
    "\n",
    "class OutlierHandling(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, method='KNN'):\n",
    "    self.method=method\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    if self.method=='KNN':\n",
    "      return KNNOutliers(X)\n",
    "    elif self.method=='Z':\n",
    "      return ZOutliers(X)\n",
    "    elif self.method=='IQR':\n",
    "      return OutlierDetection(X)\n",
    "    else:\n",
    "      raise ValueError(\"Invalid outlier detection method\")\n",
    "    \n",
    "def outliertest(df):\n",
    "  KNN=KNNOutliers(df)\n",
    "  Z=ZOutliers(df)\n",
    "  IQR=OutlierDetection(df)\n",
    "  Outliers=[KNN,Z,IQR]\n",
    "  regressionresults={}\n",
    "  for i, outlier in enumerate(Outliers):\n",
    "    outlier_indeces=outlier.index.tolist()\n",
    "    outlier_indeces=[idx for idx in outlier_indeces if idx in df.index]\n",
    "    cleandf=df.drop(index=outlier_indeces)\n",
    "    X=cleandf.iloc[:,1:9].values\n",
    "    y=cleandf['Medvalue'].values\n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    clf=RandomForestRegressor()\n",
    "    CLFDT=DecisionTreeRegressor()\n",
    "    clf.fit(x_train,y_train)\n",
    "    CLFDT.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    y_predDT=CLFDT.predict(x_test)\n",
    "    print(f\"Mean Squared Error for Random Forest for {i + 1}: {mean_squared_error(y_test,y_pred)}\")\n",
    "    print(f\"R2 Score for Random Forest for {i + 1}: {r2_score(y_test,y_pred)}\")\n",
    "    print(f\"Mean Squared Error for Decision Tree for {i + 1}: {mean_squared_error(y_test,y_predDT)}\")\n",
    "    print(f\"R2 Score for Decision Tree for {i + 1}: {r2_score(y_test,y_predDT)}\")\n",
    "    regressionresults[f\"Outlier Method {i + 1}\"] = {\n",
    "        \"RandomForest\": {\n",
    "            \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n",
    "            \"R2 Score\": r2_score(y_test, y_pred)\n",
    "        },\n",
    "        \"DecisionTree\": {\n",
    "            \"Mean Squared Error\": mean_squared_error(y_test, y_predDT),\n",
    "            \"R2 Score\": r2_score(y_test, y_predDT)\n",
    "        }\n",
    "    }\n",
    "  random_mse=[regressionresults[method]['RandomForest']['Mean Squared Error'] for method in regressionresults]\n",
    "  random_r2=[regressionresults[method]['RandomForest']['R2 Score'] for method in regressionresults]\n",
    "  decision_mse=[regressionresults[method]['DecisionTree']['Mean Squared Error'] for method in regressionresults]\n",
    "  decision_r2=[regressionresults[method]['DecisionTree']['R2 Score'] for method in regressionresults]\n",
    "  fig,ax=plt.subplots(2,2, figsize=(12,12))\n",
    "  plt.bar(['IQR','KNN','ZOutliers'],random_mse,width=1, edgecolor='red', color='blue')\n",
    "  plt.title('Random Forest Mean Squared Error')\n",
    "  plt.subplot(2,2,1)\n",
    "  plt.bar(['IQR','KNN','ZOutliers'],random_r2,width=1, edgecolor='red', color='blue')\n",
    "  plt.title('Random Forest R2 Score')\n",
    "  plt.subplot(2,2,2)\n",
    "  plt.bar(['IQR','KNN','ZOutliers'],decision_mse,width=1, edgecolor='red', color='blue')\n",
    "  plt.title('Decision Tree Mean Squared Error')\n",
    "  plt.subplot(2,2,3)\n",
    "  plt.bar(['IQR','KNN','ZOutliers'],decision_r2,width=1, edgecolor='red', color='blue')\n",
    "  plt.title('Decision Tree R2 Score')\n",
    "  plt.subplot(2,2,4)\n",
    "  plt.show()\n",
    "outliertest(df_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms for House Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_housing['HouseAge'], kde=True, color='green', bins=30)\n",
    "plt.title(\"Distribution of House Age\")\n",
    "plt.xlabel(\"House Age (Years)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transformation of Median House Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_housing['MedHouseVal_log'] = np.log1p(df_housing['MedHouseVal'])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_housing['MedHouseVal_log'], kde=True, color='blue', bins=30)\n",
    "plt.title(\"Log-Transformed Distribution of Median House Value\")\n",
    "plt.xlabel(\"Log Median House Value ($100,000)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the boxplot of the log-transformed median house value by median income quintiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_housing['MedInc_quintile'] = pd.qcut(df_housing['MedInc'], 5)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='MedInc_quintile', y='MedHouseVal_log', data=df_housing, palette=\"cool\")\n",
    "plt.title(\"Log-Transformed Median House Value by Median Income Quintiles\")\n",
    "plt.xlabel(\"Median Income (Quintiles)\")\n",
    "plt.ylabel(\"Log Median House Value ($100,000)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watson's GeoPandas Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Data'''\n",
    "common_crs = \"EPSG:4269\"\n",
    "coastline_shp = './geoData/califorina_pacific_coast-shapefile/3853-s3_2002_s3_reg_pacific_ocean.shp'\n",
    "places_shp = './geoData/ca_places/CA_Places.shp'\n",
    "counties_shp = './geoData/us_county/tl_2023_us_county.shp'\n",
    "# counties_shp = './geoData/ca_counties/CA_Counties.shp'\n",
    "\n",
    "\n",
    "coastline = gpd.read_file(coastline_shp)\n",
    "places = gpd.read_file(places_shp)\n",
    "counties = gpd.read_file(counties_shp)\n",
    "\n",
    "rawData = fetch_california_housing(as_frame=True)\n",
    "cal_housing_geo = gpd.GeoDataFrame(rawData.data, geometry=gpd.points_from_xy(rawData.data.Longitude, rawData.data.Latitude), crs=common_crs)\n",
    "cal_housing_geo['y'] = rawData.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Coordinate Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline = coastline.to_crs(common_crs)\n",
    "places = places.to_crs(common_crs)\n",
    "counties = counties.to_crs(common_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Set Geo Bounding Box and Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "housing_bounds = cal_housing_geo.total_bounds\n",
    "counties = counties.clip(housing_bounds)\n",
    "coastline = coastline.clip(housing_bounds)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), tight_layout=True)\n",
    "\n",
    "coastline.plot(ax=ax, edgecolor='blue', linewidth=0.1)\n",
    "counties.boundary.plot(ax=ax, edgecolor='black', linewidth=.5)\n",
    "cal_housing_geo.plot(ax=ax, color='red', linewidth=0.1)\n",
    "places.plot(ax=ax, color='green', linewidth=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineer From Coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_to_coast = gpd.sjoin_nearest(cal_housing_geo, coastline, how=\"left\", distance_col=\"meters\")\n",
    "cal_housing_geo['m_to_coast'] = house_to_coast['meters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineer Distance from Census Designated Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "house_to_interest = gpd.sjoin_nearest(cal_housing_geo, places, how=\"left\", distance_col=\"meters\")\n",
    "# cal_housing_geo['CDP'] = house_to_interest['NAME'] // The name of the CDP does not appear to impact model performance\n",
    "cal_housing_geo['m_to_CDP'] = house_to_interest['meters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineer County Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This data point does not appear to impact model performance, but can be useful for EDA.\n",
    "# house_to_county = gpd.sjoin_nearest(cal_housing_geo, counties, how=\"left\")\n",
    "# cal_housing_geo['county_name'] = house_to_county['NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color Code Counties by Target Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edaData = gpd.GeoDataFrame(rawData.data, geometry=gpd.points_from_xy(rawData.data.Longitude, rawData.data.Latitude), crs=common_crs)\n",
    "edaData['y'] = rawData.target\n",
    "\n",
    "house_to_county = gpd.sjoin_nearest(edaData, counties, how=\"left\")\n",
    "edaData['county_name'] = house_to_county['NAME']\n",
    "\n",
    "meanTarget = edaData.groupby('county_name')['y'].mean().reset_index()\n",
    "\n",
    "print(meanTarget[meanTarget['county_name'] == 'Alameda']['y'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Mean Target Value to County Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTarget = edaData.groupby('county_name')['y'].mean().reset_index()\n",
    "\n",
    "def setMeanTarget(row):\n",
    "    value = meanTarget[meanTarget['county_name'] == row['NAME']]['y'].array\n",
    "    row['mean_target'] = value[0] if len(value) else None\n",
    "    return row\n",
    "\n",
    "withTarget = counties.apply(setMeanTarget, axis=1)\n",
    "withTarget.dropna(subset='mean_target')\n",
    "\n",
    "withTarget.plot(column='mean_target', legend=True)\n",
    "plt.title('Median Home Value')\n",
    "\n",
    "# cal_housing_geo = encode(cal_housing_geo, ['CDP','county_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Default Regressor Timeline to determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData = cal_housing_geo.drop(columns=['y', 'geometry'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(modelData, rawData.target, test_size=0.3, random_state=42)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('regress',RandomForestRegressor())], verbose=True)\n",
    "predicted = pipe.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "print(mse)\n",
    "\n",
    "regressor = pipe.steps[-1][-1]\n",
    "\n",
    "feat_importance = list(zip(modelData.columns,regressor.feature_importances_))\n",
    "feat_importance = sorted(feat_importance, key=lambda tup: tup[1])\n",
    "\n",
    "feat=[x for x,y in feat_importance]\n",
    "importance=[y for x,y in feat_importance]\n",
    "\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "sns.barplot(y=feat, x=importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mike's GeoPandas Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load School District Information and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolsfile='/content/drive/MyDrive/schools.shp'\n",
    "os.environ['SHAPE_RESTORE_SHX'] = 'YES'\n",
    "schools=gpd.read_file(schoolsfile)\n",
    "schools['unique_id'] = range(1, len(schools) + 1)\n",
    "\n",
    "print(schools.info())\n",
    "print(schools.nunique())\n",
    "\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "cal_df=pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
    "cal_df['Medvalue'] = housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip latitude and longitude together to facilitate sJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong = [Point(xy) for xy in zip(cal_df['Longitude'], cal_df['Latitude'])]\n",
    "new_df = gpd.GeoDataFrame(cal_df, geometry=latlong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot xy coordinates over district map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=schools.plot(figsize=(10,10), alpha=0.5, edgecolor='k')\n",
    "new_df.plot(ax=ax, column='Medvalue', cmap='coolwarm', markersize=5, legend=True)\n",
    "plt.title('California Housing Prices and Schools')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SJoin Cal Housing dataset with School districts, and build new features based upon median income per district and population density for each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joineddf=gpd.sjoin(schools, new_df, how='left', predicate='intersects')\n",
    "\n",
    "# print(joineddf.nunique())\n",
    "# print(joineddf.isnull().sum())\n",
    "# print(joineddf.duplicated(subset='unique_id').sum())\n",
    "\n",
    "\n",
    "joineddf['schooldistrictmedianincome']=joineddf.groupby('unique_id')['MedInc'].transform('mean')\n",
    "joineddf['populationdensity']=joineddf.groupby('unique_id')['Population'].transform('mean')\n",
    "joineddf=joineddf.dropna()\n",
    "print(joineddf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run each feature over the district map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=schools.plot(figsize=(10,10), alpha=0.5, edgecolor='k')\n",
    "joineddf.plot(ax=ax, column='schooldistrictmedianincome', cmap='coolwarm', markersize=5, legend=True)\n",
    "plt.title('California Median Income aligned with School Districts')\n",
    "plt.show()\n",
    "ax=schools.plot(figsize=(10,10), alpha=0.5, edgecolor='k')\n",
    "joineddf.plot(ax=ax, column='populationdensity', cmap='coolwarm', markersize=5, legend=True)\n",
    "plt.title('California School Districts aligned with average population')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run default Decision Tree and Random Forest Classifiers to determine feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegressionAnalysis(df):\n",
    "  df=joineddf.drop(columns=['Medvalue','geometry'])\n",
    "  X=df.values\n",
    "  y=joineddf['Medvalue'].values\n",
    "  scaler = StandardScaler()\n",
    "  X=scaler.fit_transform(X)\n",
    "  x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "  clf=RandomForestRegressor()\n",
    "  CLFDT=DecisionTreeRegressor()\n",
    "  clf.fit(x_train,y_train)\n",
    "  CLFDT.fit(x_train,y_train)\n",
    "  y_pred=clf.predict(x_test)\n",
    "  y_predDT=CLFDT.predict(x_test)\n",
    "  print(f\"Mean Squared Error for Random Forest: {mean_squared_error(y_test,y_pred)}\")\n",
    "  print(f\"R2 Score for Random Forest: {r2_score(y_test,y_pred)}\")\n",
    "  print(f\"Mean Squared Error for Decision Tree: {mean_squared_error(y_test,y_predDT)}\")\n",
    "  print(f\"R2 Score for Decision Tree: {r2_score(y_test,y_predDT)}\")\n",
    "  importances = clf.feature_importances_\n",
    "  feature_imp_df = pd.DataFrame({'Feature': df.columns, 'Gini Importance': importances}).sort_values('Gini Importance', ascending=False) \n",
    "  print(feature_imp_df)\n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.barh(df.columns, importances, color='skyblue')\n",
    "  plt.xlabel('Feature Importance')\n",
    "  plt.title('Feature Importance')\n",
    "  plt.gca().invert_yaxis()  \n",
    "  plt.show()\n",
    "  return y_pred,y_test,y_predDT\n",
    "  \n",
    "\n",
    "RegressionAnalysis(joineddf)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
